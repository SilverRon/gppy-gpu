import os
import re
import glob
from datetime import datetime
from astropy.io import fits


def to_datetime_string(datetime_str, date_only=False):
    """
    Convert an ISO-formatted datetime string to a specific string representation.

    This function handles datetime strings with timezone information, converting
    them to a standardized format for astronomical data processing.

    Args:
        datetime_str (str): ISO-formatted datetime string (e.g., '2025-02-07T16:44:41+09:00')
        date_only (bool, optional): If True, returns only the date. Defaults to False.

    Returns:
        str: Formatted datetime string
            - With date_only=False: 'YYYYMMDD_HHMMSS' (e.g., '20250207_164441')
            - With date_only=True: 'YYYYMMDD' (e.g., '20250207')

    Example:
        >>> to_datetime_string('2025-02-07T16:44:41Z')
        '20250207_164441'
        >>> to_datetime_string('2025-02-07T16:44:41Z', date_only=True)
        '20250207'
    """
    dt = datetime.fromisoformat(datetime_str.replace("Z", "+00:00"))

    # Format to desired output
    if date_only:
        return dt.strftime("%Y%m%d")
    else:
        return dt.strftime("%Y%m%d_%H%M%S")


def header_to_dict(file_path):
    """
    Parse a FITS header text file and convert it into a dictionary.

    This function reads a text file containing a FITS (Flexible Image Transport System)
    header generated by the `imhead` command, extracts key-value pairs from each line,
    and stores them in a dictionary.

    The function handles the following cases:
    - String values enclosed in single quotes are stripped of quotes and whitespace.
    - Numerical values are converted to integers or floats when possible.
    - Boolean values (`T` and `F` in FITS format) are converted to Python `True` and `False`.
    - Comments after the `/` character are ignored.

    Args:
        file_path (str): Path to the text file containing the FITS header.

    Returns:
        dict: A dictionary containing the parsed header, where keys are the FITS
        header keywords and values are the corresponding parsed values.

    Example:
        Given a FITS header file with the following lines:
            SIMPLE  = T / file does conform to FITS standard
            BITPIX  = 8 / number of bits per data pixel
            NAXIS   = 0 / number of data axes
            EXTEND  = T / FITS dataset may contain extensions

        The function will return:
        {
            "SIMPLE": True,
            "BITPIX": 8,
            "NAXIS": 0,
            "EXTEND": True
        }
    """
    # Regular expression to match FITS header format
    fits_pattern = re.compile(r"(\S+)\s*=\s*(.+?)(?:\s*/\s*(.*))?$")

    fits_dict = {}
    # Read the FITS header from the text file
    with open(file_path, "r", encoding="utf-8") as file:
        for line in file:
            match = fits_pattern.match(line)
            if match:
                key, value, comment = match.groups()
                value = value.strip()

                # Handle string values enclosed in single quotes
                if value.startswith("'") and value.endswith("'"):
                    value = value.strip("'").strip()

                # Convert numerical values
                else:
                    try:
                        if "." in value:
                            value = float(
                                value
                            )  # Convert to float if it contains a decimal
                        else:
                            value = int(value)  # Convert to integer otherwise
                    except ValueError:
                        pass  # Leave as string if conversion fails

                # Convert boolean values (T/F in FITS format)
                if value == "T":
                    value = True
                elif value == "F":
                    value = False

                fits_dict[key] = value

    return fits_dict


def get_camera(header):
    """
    Determine the camera type based on image dimensions.

    Identifies the camera model by examining the number of pixels in the first axis.
    Supports two camera types: C3 and C5.
    Support for the overscan area of C5 is to be added.

    Args:
        header (dict or str): Either a header dictionary or a path to a .head file

    Returns:
        str: Camera type ('C3', 'C5', or 'Unidentified')

    Example:
        >>> get_camera({'NAXIS1': 9576, 'NAXIS2': 6388})
        'C3'
        >>> get_camera('/path/to/header.head')
        'C5'
    """
    if type(header) == dict:
        pass
    else:
        header = header_to_dict(header)

    # if header["NAXIS1"] == 9576:  # NAXIS2 6388
    #     return "C3"
    # elif header["NAXIS1"] == 14208:  # NAXIS2 10656
    #     return "C5"
    if 9576 % header["NAXIS1"] == 0:  # NAXIS2 6388
        return "C3"
    elif 14208 % header["NAXIS1"] == 0:  # NAXIS2 10656
        return "C5"
    else:
        return "Unidentified"


def find_raw_path(unit, date, n_binning, gain):
    """
    Locate the raw data directory for a specific observation.

    Searches for raw data directories with increasing specificity:
    1. By unit and date
    2. By unit, date, and gain
    3. By unit, date, binning, and gain

    Args:
        unit (str): Observation unit identifier
        date (str): Observation date
        n_binning (int): Pixel binning factor
        gain (float): Detector gain setting

    Returns:
        str: Path to the raw data directory

    Raises:
        ValueError: If no matching data directory is found
    """
    from .const import RAWDATA_DIR

    raw_data_folder = glob.glob(f"{RAWDATA_DIR}/{unit}/{date}*")

    if len(raw_data_folder) > 1:
        raw_data_folder = glob.glob(f"{RAWDATA_DIR}/{unit}/{date}*_gain{gain}*")
        if len(raw_data_folder) > 1:
            raw_data_folder = glob.glob(
                f"{RAWDATA_DIR}/{unit}/{date}_{n_binning}x{n_binning}_gain{gain}*"
            )

    elif len(raw_data_folder) == 0:
        raise ValueError("No data folder found")

    return raw_data_folder[0]


def parse_exptime(filename, return_type="float"):
    """
    Extract exposure time from a filename.

    Args:
        filename (str): Filename containing exposure time
        return_type (type, optional): Return type for exposure time. Defaults to float.

    Returns:
        float or int: Exposure time extracted from the filename

    Example:
        >>> parse_exptime('image_100.0s_data.fits')
        100.0
        >>> parse_exptime('image_100.0s_data.fits', return_type=int)
        100
    """
    exptime = float(re.search(r"_(\d+\.\d+)s_", filename).group(1))
    return int(exptime) if return_type == int else exptime


def define_output_dir(date, n_binning, gain, obj=None, unit=None, filt=None):
    """
    Generate a standardized output directory name.

    Args:
        date (str): Observation date
        n_binning (int): Pixel binning factor
        gain (float): Detector gain setting

    Returns:
        str: Formatted output directory name

    Example:
        >>> define_output_dir('20250207', 2, 1.0)
        '20250207_2x2_gain1.0'
    """
    if obj:
        if unit:
            if filt:
                return f"{date}_{n_binning}x{n_binning}_gain{gain}/{obj}/{unit}/{filt}"
            else:
                return f"{date}_{n_binning}x{n_binning}_gain{gain}/{obj}/{unit}"
        else:
            return f"{date}_{n_binning}x{n_binning}_gain{gain}/{obj}"
    else:
        return f"{date}_{n_binning}x{n_binning}_gain{gain}"


def lapse(explanation="elapsed", print_output=True):
    """
    Measure and report elapsed time using a global checkpoint.

    A utility function for performance tracking and logging elapsed time
    between function calls. It supports various time unit representations
    and optional console output.

    Args:
        explanation (str, optional): Description for the elapsed time report.
            Defaults to "elapsed".
        print_output (bool, optional): Whether to print the time report.
            Defaults to True.

    Returns:
        float: Elapsed time in seconds

    Usage:
        >>> lapse("Start")  # Initializes the timer
        >>> # Do some work
        >>> lapse("Task completed")  # Prints elapsed time
    """
    from timeit import default_timer as timer

    global _dhutil_lapse_checkpoint  # Global Checkpoint

    current_time = timer()

    if _dhutil_lapse_checkpoint is None:  # Initialize if it's the first call
        _dhutil_lapse_checkpoint = current_time
    else:
        elapsed_time = current_time - _dhutil_lapse_checkpoint

        if elapsed_time < 60:
            dt, unit = elapsed_time, "seconds"
        elif elapsed_time > 3600:
            dt, unit = elapsed_time / 3600, "hours"
        else:
            dt, unit = elapsed_time / 60, "minutes"

        _dhutil_lapse_checkpoint = current_time  # Update the checkpoint

        print_str = f"{dt:.3f} {unit} {explanation}"
        print(print_str)  # log the elapsed time at INFO level

        if print_output:
            print(print_str, end="\n")  # log the elapsed time
        return elapsed_time  # in seconds


def add_padding(header, n, copy_header=False):
    """
    Add empty COMMENT entries to a FITS header to ensure specific block sizes.

    This function helps manage FITS header sizes by adding padding comments.
    Useful for maintaining specific header block structures required by
    astronomical data processing tools.

    Args:
        header (fits.Header): Input FITS header
        n (int): Target number of 2880-byte blocks
        copy_header (bool, optional): If True, operates on a copy of the header.
            Defaults to False. Note: Using True is slower.

    Returns:
        fits.Header: Header with added padding comments

    Note:
        - Each COMMENT is 80 bytes long
        - The total header size must be a multiple of 2880 bytes
    """
    if copy_header:
        import copy

        header = copy.deepcopy(header)

    info_size = len(header.cards) * 80

    target_size = (n - 1) * 2880  # fits header size is a multiple of 2880 bytes
    padding_needed = target_size - info_size
    num_comments = padding_needed // 80  # (each COMMENT is 80 bytes)

    # CAVEAT: END also uses one line.
    # for _ in range(num_comments - 1):  # <<< full n-1 2880-byte blocks
    for _ in range(num_comments):  # <<< marginal n blocks
        header.add_comment(" ")

    return header


def remove_padding(header):
    """
    Remove COMMENT padding from a FITS header.

    Strips all trailing COMMENT entries, returning a header with only
    significant entries.

    Args:
        header (fits.Header): Input FITS header with potential padding

    Returns:
        fits.Header: Header with padding comments removed

    Note:
        This method is primarily useful for header inspection and may not
        be directly applicable for header updates.
    """
    # Extract all header cards
    cards = list(header.cards)

    # Find the last non-COMMENT entry
    for i in range(len(cards) - 1, -1, -1):
        if cards[i][0] != "COMMENT":  # i is the last non-comment idx
            break

    return header[: i + 1]


def read_header(file):
    """
    Read and clean a FITS header file, normalizing unicode and correcting WCS types.

    Args:
        file (str): Path to the header file

    Returns:
        fits.Header: Processed and cleaned FITS header with corrected WCS types

    Note:
        - Removes non-ASCII characters
        - Converts WCS projection type from TAN to TPV
    """

    try:
        import unicodedata

        with open(file, "r", encoding="utf-8") as f:
            content = f.read()

        # Clean non-ASCII characters
        cleaned_string = (
            unicodedata.normalize("NFKD", content).encode("ascii", "ignore").decode("ascii")
        )

        # Correct CTYPE (TAN --> TPV)
        hdr = fits.Header.fromstring(cleaned_string, sep="\n")
        hdr["CTYPE1"] = ("RA---TPV", "WCS projection type for this axis")
        hdr["CTYPE2"] = ("DEC--TPV", "WCS projection type for this axis")
        return hdr
    except:
        with fits.open(file, mode="readonly") as hdul:
            hdr = hdul[0].header
        return hdr

def update_padded_header(target_fits, header_new):
    """
    Update a FITS file's header with header_new (scamp or photometry output).
    header_new can be either astropy.io.fits.Header or dict.

    CAVEAT: This overwrites COMMENTs adjacent to the padding

    Args:
        target_fits (str): Path to the target FITS file to be updated
        header_new (dict or Header): Header object with info to be added

    Note:
        - Modifies the target FITS file in-place
        - Preserves existing non-COMMENT header entries
        - Appends or replaces header cards from the input header
    """

    with fits.open(target_fits, mode="update") as hdul:
        header = hdul[0].header
        cards = header.cards
        for i in range(len(cards) - 1, -1, -1):
            if cards[i][0] != "COMMENT":  # i is the last non-comment idx
                break

        # format new header for iteration
        if isinstance(header_new, fits.Header):
            cardpack = header_new.cards
        elif isinstance(header_new, dict):  # (key, value) or (key, (value, comment))
            cardpack = [
                (key, *value) if isinstance(value, tuple) else (key, value)
                for key, value in header_new.items()
            ]
        else:
            raise ValueError("Unsupported Header format for updating padded Header")

        # Expects (key, value, comment)
        for j, card in enumerate(cardpack):
            if i + j <= len(cards) - 1:
                del header[i + j]
                header.insert(i + j, card)
            else:
                header.append(card, end=True)


class Parse7DS:
    """
    Parser for 7DT fits files
    obsdata: 7DT11_20250102_050704_T00223_m425_1x1_100.0s_0001.fits
    processed: calib_7DT11_T09282_20241017_060927_m425_100.fits
    """

    def __init__(self, file):
        self.path = os.path.abspath(file)
        self.basename = os.path.basename(file)
        self.stem, self.ext = os.path.splitext(self.basename)
        if self.ext != ".fits":
            raise ValueError("Not a FITS file")
        self.parts = self.stem.split("_")

        self.type = self.identify_type
        if self.type == "obsdata":
            self.parse_obsdata()
        elif self.type == "processed":
            self.parse_processed()
        else:
            return None

    @property
    def identify_type(self):
        if self.stem.startswith("7DT"):
            return "obsdata"
        elif self.stem.startswith("calib"):
            return "processed"
        else:
            return None

    def parse_obsdata(self):
        self.unit = self.parts[0]
        self.date = self.parts[1]
        self.time = self.parts[2]
        self.obj = self.parts[3]
        self.filter = self.parts[4]
        self.n_binning = self.parts[5]
        self.exptime = self.parts[6]

    def parse_processed(self):
        self.unit = self.parts[1]
        self.obj = self.parts[2]
        self.date = self.parts[3]
        self.time = self.parts[4]
        self.filter = self.parts[5]
        self.exptime = self.parts[6]
